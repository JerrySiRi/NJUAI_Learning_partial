{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2：\n",
    "\n",
    "⾃动编码器模型（AE）；变分⾃动编码器模型（VAE）；条件变分⾃动编码器模型（Conditional VAE）\n",
    "\n",
    "并将模型应⽤到MNIST 数据上对⼿写体数字进⾏降维、聚类、⽣成和指定⽣成⼯作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FC layer实现AE、VAE、CVAE & 画图展示\n",
    "\n",
    "### 1.1 AE、VAE、CVAE架构搭建\n",
    " \n",
    "#### 1.1.1 通用部件Encoder & Decoder的实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Encoder实现\n",
    "\n",
    "condition_size = 10 #10个数字，用一个10维向量作为CVAE的条件（0-9十个数字，依label给出one-hot编码）\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def onehot(label): # CVAE为了要和input（1*28*28）可以concatenate，需要扩展成3维的(后续还有batch_size就变成三维)\n",
    "    label = label.unsqueeze(1)\n",
    "    label = label.unsqueeze(2)\n",
    "    #print(label.size(0))\n",
    "    exp_vec = torch.zeros(label.size(0), 1, condition_size).to(device)\n",
    "    # 【新创建的，和已在cuda上tensor无关，不知道应该放在哪里！！！】\n",
    "    exp_vec.scatter_(2, label, 1) # 根据label，对exp_vec进行操作，填写到维度为1的对应位置\n",
    "    return exp_vec\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_size, latent_size, arch=\"AE\", **kwargs) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.mu = nn.Sequential(nn.Linear(x_dim, hidden_size), nn.ReLU(), nn.Linear(hidden_size, latent_size),)\n",
    "        self.arch = arch\n",
    "        if self.arch != \"AE\":  # 若encoder返回的是均值与标准差(VAE、CVAE), 需要额外生成mu和sigma（两架构可以一样）\n",
    "            self.sigma = nn.Sequential(nn.Linear(x_dim, hidden_size), nn.ReLU(), nn.Linear(hidden_size, latent_size),)\n",
    "\n",
    "        if self.arch == \"CVAE\":\n",
    "            self.mu = nn.Sequential(nn.Linear(x_dim+condition_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, latent_size),)\n",
    "            self.sigma = nn.Sequential(nn.Linear(x_dim+condition_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, latent_size),)\n",
    "\n",
    "    def forward(self, xs, label=None):# 只有CVAE才会传入label，xs是输入的图片，784*1*batchsize\n",
    "        # 实现编码器的forward过程，arch架构的不同取值意味着我们需要不同输出的encoder\n",
    "\n",
    "        if self.arch == \"AE\":\n",
    "            output = self.mu(xs) # AE的输出，只有一个code\n",
    "        elif self.arch == \"VAE\":# VAE的输出，有mu和sigma两个输出\n",
    "            sigma = self.sigma(xs)\n",
    "            output = (mu,sigma)\n",
    "        else: # CVAE的输出，有mu和sigma两个，但是输入还有希望生成数据的label！先扩展、再concatenate起来\n",
    "            label = onehot(label)\n",
    "            # print(\"dim_image\",xs.shape)\n",
    "            # print(\"label_image\",label.shape)\n",
    "            xs= torch.cat((xs, label), dim=-1)\n",
    "            # xs = xs.to(device)     # Bug：不用等号赋值，就没办法移动到cuda上！\n",
    "            mu = self.mu(xs)\n",
    "            sigma = self.sigma(xs)\n",
    "            output = (mu,sigma)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decoder的实现\n",
    "# 不同的自编码器可能需要不同的输入, 借助**kwargs来处理.\n",
    "# Review：**收集所有未匹配的关键字参数组成一个dict对象，局部变量kwargs指向此dict对象\n",
    "# 对于AE的情况, 只需要zs作为输入即可,\n",
    "# 对于VAE,CVAE的情况, 我们可能需要code服从分布的均值与方差(对于CVAE, 还需要类别的指示变量)\n",
    "\n",
    "# 在实现遇到迷茫的时候, 不妨考虑具体的自编码器类需要什么样的encoder, decoder.\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_size, latent_size, arch=\"AE\", **kwargs) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.arch = arch\n",
    "        if self.arch == \"AE\":\n",
    "            self.decoder = nn.Sequential(nn.Linear(latent_size, hidden_size), nn.ReLU(), \n",
    "            nn.Linear(hidden_size, x_dim),)\n",
    "        elif self.arch == \"VAE\": # 需要传入encoder的均值和方差 \n",
    "            self.decoder = nn.Sequential(nn.Linear(latent_size, hidden_size), nn.ReLU(), \n",
    "            nn.Linear(hidden_size, x_dim),)\n",
    "        elif self.arch == \"CVAE\":\n",
    "            self.decoder = nn.Sequential(nn.Linear(latent_size+condition_size, hidden_size), nn.ReLU(), \n",
    "            nn.Linear(hidden_size, x_dim),)  \n",
    "\n",
    "    def forward(self, zs,label=None, **otherinputs): # 【【此时的zs已经是经过处理过的，已经是N(mu,sigma^2)中sample出来的值了】】\n",
    "        # 实现decoder的decode部分,此时就假定直接输出图片了，不再生成mu和sigma再sample\n",
    "        if self.arch == \"AE\":\n",
    "            output = self.decoder(zs)\n",
    "        elif self.arch == \"VAE\":\n",
    "            output = self.decoder(zs)\n",
    "        elif self.arch == \"CVAE\":\n",
    "            label = onehot(label)\n",
    "            zs = torch.cat((zs, label), dim=-1)\n",
    "            output = self.decoder(zs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 基于通用部件的AE、VAE、CVAE实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, **kwargs) -> None:\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "class VAE(nn.Module): # 要同时返回中间参数mu和sigma的，用于后续计算kl loss\n",
    "    def __init__(self,encoder,decoder,**kwargs) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self,x):\n",
    "        mu,sigma = self.encoder(x) # 【encoder的forward函数返回了两个参数！！！】\n",
    "        # epsilon = torch.randn(mu) # 生成了很多个正态分布！！！mu是一个latent_size大小的，每一个分量是一个正态参数\n",
    "        # z = mu + epsilon*sigma\n",
    "        # 【更优！加入随机噪声！！！对encoder输出进行简单处理，且保证是正数！】\n",
    "        std = torch.exp(0.5 * sigma)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = epsilon * std + mu\n",
    "        return mu, sigma, self.decoder(z)\n",
    "\n",
    "    def generate(self,new_code):\n",
    "        new_code = new_code.to(device) \n",
    "        return self.decoder(new_code) # 【假设此时new_code被用户经过正态分布的处理了！】\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self,encoder,decoder,**kwargs) -> None:\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = encoder #【【【小心！传入时arch必须设定成 “CVAE”】】】\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self,x,label):# label必须传入\n",
    "        mu,sigma =self.encoder(x,label)# 【forward返回两参数，其中input已经concatenate了】\n",
    "        std = torch.exp(0.5 * sigma)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = epsilon * std + mu\n",
    "        return mu, sigma, self.decoder(z,label) # decoder中再合并\n",
    "\n",
    "    def generate(self,new_code,label): # 【假设此时new_code被用户经过正态分布的处理了！label就是一个数字】\n",
    "        new_code = new_code.to(device)\n",
    "        label = label.to(device)\n",
    "        return self.decoder(new_code,label)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 模型训练\n",
    "\n",
    "## 1.2.1 损失函数\n",
    "其中值得注意的是VAE及CVAE为了防止过拟合而引入的KL散度，作为损失函数的衡量标准之一\n",
    "$$KL(\\mathcal{N}(\\mu,\\sigma ^2)||\\mathcal{N}(0,1) ) = -\\frac{1}{2}(\\log (\\sigma ^2)-\\sigma ^2-\\mu^2+1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练中损失函数\n",
    "# AE：MSE\n",
    "# VAE & CVAE：KL loss + MSE \n",
    "\n",
    "# 【可调节超参数：kl散度在epoch增加后所占loss的权重】\n",
    "aging_rate = 0.3\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self, arch=\"AE\", choice=\"BCE\", **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.choice = choice\n",
    "    def recon_loss(self, x, x_): # 重构损失\n",
    "        if self.choice == \"L1\": # L1\n",
    "            loss = nn.L1Loss(x, x_)  # 【【BUG？必须选择这个？】】\n",
    "        else: # BCE\n",
    "            loss = F.binary_cross_entropy(F.sigmoid(x_),F.sigmoid(x), reduction='sum')\n",
    "        return loss\n",
    "\n",
    "    def kl_div(self, mu,sigma): # KL loss\n",
    "        return  -0.5 * torch.mean(torch.log(sigma.pow(2)) - sigma.pow(2) - mu.pow(2) + 1)\n",
    "\n",
    "    def forward(self, x, x_, mu=None, sigma=None, **otherinputs):# loss的计算\n",
    "        loss = Loss.recon_loss(self,x,x_)# 可选choice = \"L1\"\n",
    "        if self.arch == \"AE\":\n",
    "            total_loss = loss\n",
    "        elif self.arch == \"VAE\" or self.arch==\"CVAE\":\n",
    "            kl_loss = Loss.kl_div(self,mu,sigma)\n",
    "            total_loss = loss + kl_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数，可以在x.reshape中调整！\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "def train_epoch(model, train_loader, loss, optimizer, epoch, epoch_num, arch):\n",
    "    \"\"\"\n",
    "    main中需要传入的参数\n",
    "    model：是AE、VAE、CVAE的model（类的实例）\n",
    "    train_loader：main中导入的minist数据集\n",
    "    loss：定义的损失函数类的实例中的函数\n",
    "    optimizer：torch中自带的优化器\n",
    "    epoch：当前迭代优化轮数\n",
    "    epoch_num：一共迭代优化的轮数\n",
    "    arch：当前选择的model的名字（字符串）\n",
    "    \"\"\"\n",
    "    model.train() # 调用继承的父类nn.Module的方法，所有子模块调整为训练模式\n",
    "    train_loss = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        # 【【【只需要把所有训练数据（x，y）放到cuda上就可以啦！！！其他的自动依据device判断位置】】】\n",
    "        y = y.to(device)\n",
    "        # Review：enumerate把可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
    "        # 既可以直接访问该对象，又可以通过索引来访问！\n",
    "        x = x.reshape(128, 1, -1)  \n",
    "        # 生成(128,1,784)，原来batch_size对应的特征矩阵是128*1*28*28，\n",
    "        # 其实四维和三维的效果一样，28*28每个pixel都是要作为一个neuron作为input的！\n",
    "        if arch == \"AE\":\n",
    "            # x_ = model.forward(x)\n",
    "            x_ = model(x)     \n",
    "            \"\"\"\n",
    "            自动调用 forward 函数原因分析：\n",
    "            利用Python的语言特性，y = model(x)是调用了对象model的__call__方法，\n",
    "            而nn.Module把__call__方法实现为类对象的forward函数，\n",
    "            所以任意继承了nn.Module的类对象都可以这样简写来调用forward函数。\n",
    "            \"\"\"\n",
    "            loss_num = loss(x, x_) # 同理，自动调用loss中的forward方法！！！\n",
    "        elif  arch == \"VAE\":\n",
    "            # mu, log_var, x_= model.forward(x)\n",
    "            mu, sigma, x_= model(x)\n",
    "            loss_num = loss(x, x_,mu,sigma)\n",
    "        elif  arch == \"CVAE\":\n",
    "            # mu, log_var, x_ = model.forward(x,y)# y是train data的真实label\n",
    "            mu, sigma, x_ = model(x,y)# y是train data的真实label\n",
    "            loss_num = loss(x, x_,mu,sigma)\n",
    "        train_loss += loss_num # 在此处计算总loss\n",
    "        optimizer.zero_grad() # 在计算本batch_size的梯度之前，把之前的梯度清空,不做积累。只针对每一个batch中loss回溯\n",
    "        loss_num.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0: # 训练过程中的标记\n",
    "            print('Train Epoch:',epoch, i * len(x), len(train_loader.dataset),\n",
    "                       100. * i / len(train_loader),\"Loss: \",loss_num.item())\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch,\n",
    "        train_loss * 128 / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "# make_grid是张量可视化的包！！！\n",
    "# 可以协同plt一起共同操作，可以操作一下！！！\n",
    "\n",
    "def evaluate_epoch(model, test_loader, loss, epoch, epoch_num, arch):\n",
    "    model.eval() # 所有子模块调整为评估模式\n",
    "    test_loss = 0\n",
    "    with torch.no_grad(): # 评估过程，不用调整参数=不用梯度下降》》在此作用域中不会构建计算图\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)#【必须要放！】\n",
    "            x = x.reshape(128, 1, -1) # 同理，特征矩阵的三维处理\n",
    "\n",
    "            if arch == \"AE\":\n",
    "                x_ = model(x)\n",
    "                loss_num = loss(x, x_)\n",
    "                test_loss += loss_num.item()\n",
    "\n",
    "                # 保存一些重构出来的图像\n",
    "                with torch.no_grad():\n",
    "                    if i % 50 == 0:\n",
    "                        # 对照：保留原始图像数据，每50个保留一个\n",
    "                        if not os.path.exists(f\"initial_data/{arch}\"):\n",
    "                            os.makedirs(f\"initial_data/{arch}\")\n",
    "                        save_x = x.reshape(-1,1, 28, 28)[:16]#dim=0是batch_size，后面就是一个个图片的三维大小啦\n",
    "                        save_x = make_grid(save_x,8,0) # 【生成图片，可以后续使用plt在notebook展现】\n",
    "                        save_image(save_x,os.path.join(f\"initial_data/{arch}/batch_{i}.png\"))\n",
    "\n",
    "                        # 测试：对原图的重现功能\n",
    "                        if not os.path.exists(f\"results_AE/{arch}/epoch_{epoch}\"):\n",
    "                            os.makedirs(f\"results_AE/{arch}/epoch_{epoch}\")\n",
    "                        save_x_ = x_.reshape(-1, 1, 28, 28)[:16]\n",
    "                        save_x_ = make_grid(save_x_, 8, 0)\n",
    "                        save_image(save_x_, os.path.join(f\"results_AE/{arch}/epoch_{epoch}/batch_{i}.png\"))\n",
    "\n",
    "            # 只有VAE和CVAE有图像生成功能，AE就不用考虑啦！\n",
    "            elif arch == \"VAE\":\n",
    "                mu, sigma, x_ = model(x)\n",
    "                loss_num = loss(x, x_, mu, sigma)\n",
    "                test_loss += loss_num.item()\n",
    "                z = torch.randn(128,1,10)\n",
    "\n",
    "                # 测试：随机向量生成图片功能\n",
    "                sample = model.generate(z)\n",
    "                sample = sample.reshape(-1, 1, 28, 28)[:32]\n",
    "                #print(z[0],sample[0])\n",
    "                if not os.path.exists(f\"results_VAE/{arch}\"):\n",
    "                    os.makedirs(f\"results_VAE/{arch}\")\n",
    "                save_image(\n",
    "                    sample,\n",
    "                    os.path.join(f\"results_VAE/{arch}/epoch_{epoch}.png\")\n",
    "                )\n",
    "                # 【生成图片，可以后续使用plt在notebook展现】\n",
    "\n",
    "            elif arch == \"CVAE\":\n",
    "                mu, sigma, x_ = model(x,y)\n",
    "                loss_num = loss(x, x_, mu, sigma)\n",
    "                test_loss += loss_num.item()\n",
    "                z = torch.randn(128,1,10)\n",
    "\n",
    "                # 测试：随机向量生成图片功能\n",
    "                sample = model.generate(z,y)\n",
    "                sample = sample.reshape(-1, 1, 28, 28)[:32]\n",
    "                #print(z[0],sample[0])\n",
    "                # 保存一些重构出来的图像用于(写报告)进一步研究 (5/100)\n",
    "                if not os.path.exists(f\"results_CVAE/{arch}\"):\n",
    "                    os.makedirs(f\"results_CVAE/{arch}\")\n",
    "                save_image(\n",
    "                    sample,\n",
    "                    os.path.join(f\"results_CVAE/{arch}/epoch_{epoch}.png\")\n",
    "                )\n",
    "                # 【生成图片，可以后续使用plt在notebook展现】\n",
    "\n",
    "    test_loss *= 128\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集格式：28*28的灰度图像，channel = 1\n",
    "# 超参数 batch_size = 128\n",
    "\n",
    "import torch.utils.data as td\n",
    "import torchvision.datasets.mnist as mnist\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_data(wh_train=True, batch_size=128):\n",
    "    dataset = mnist.MNIST(\n",
    "        root=\"./data\",\n",
    "        train=wh_train,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                #transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.1307,], [0.3081,],),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    #for i, (x, y) in enumerate(dataset):\n",
    "        #print(i,x.shape,y)# 0 torch.Size([1, 28, 28]) \n",
    "        #print(y.shape)\n",
    "    return td.DataLoader(dataset, batch_size=batch_size,drop_last=True,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 main函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2023 13:16:05 - INFO - __main__ -   device: cuda n_gpu: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, device=device(type='cuda'), epoch_num=128, hidden_size=128, latent_size=10, type='CVAE', x_dim=784)\n",
      "\n",
      " epoch: 0\n",
      "Train Epoch: 0 0 60000 0.0 Loss:  70009.8671875\n",
      "Train Epoch: 0 6400 60000 10.683760683760683 Loss:  66352.1328125\n",
      "Train Epoch: 0 12800 60000 21.367521367521366 Loss:  65668.7734375\n",
      "Train Epoch: 0 19200 60000 32.05128205128205 Loss:  64323.59765625\n",
      "Train Epoch: 0 25600 60000 42.73504273504273 Loss:  64663.63671875\n",
      "Train Epoch: 0 32000 60000 53.41880341880342 Loss:  64285.890625\n",
      "Train Epoch: 0 38400 60000 64.1025641025641 Loss:  64887.56640625\n",
      "Train Epoch: 0 44800 60000 74.78632478632478 Loss:  64973.0078125\n",
      "Train Epoch: 0 51200 60000 85.47008547008546 Loss:  63659.11328125\n",
      "Train Epoch: 0 57600 60000 96.15384615384616 Loss:  64981.5859375\n",
      "====> Epoch: 0 Average loss: 64983.8203\n",
      "====> Test set loss: 64195.1041\n",
      "\n",
      " epoch: 1\n",
      "Train Epoch: 1 0 60000 0.0 Loss:  64385.36328125\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    encoder_args = {\n",
    "        \"x_dim\": args.x_dim,\n",
    "        \"hidden_size\": args.hidden_size,\n",
    "        \"latent_size\": args.latent_size,\n",
    "        \"arch\": args.type,\n",
    "    }\n",
    "    encoder = Encoder(**encoder_args)\n",
    "    decoder = Decoder(**encoder_args)\n",
    "    ae = {\"AE\": AE, \"VAE\": VAE, \"CVAE\": CVAE}\n",
    "\n",
    "    auto_encoder = ae[args.type](encoder, decoder) #【巧！通过字典的索引直接可以用此类来创建实例啦！】\n",
    "\n",
    "    auto_encoder.to(device)\n",
    "    # 优化器选择\n",
    "    # optimizer = torch.optim.SGD(auto_encoder.parameters(), lr=0.01)\n",
    "    optimizer =torch.optim.Adam(auto_encoder.parameters(), lr=0.001)\n",
    "    # class中用nn定义的神经网络中参数，可认为是自动加上了nn.Parameters()的处理，参数会被加入！\n",
    "    train_loader = get_data(wh_train=True, batch_size=args.batch_size)\n",
    "    test_loader = get_data(wh_train=False, batch_size=args.batch_size)\n",
    "    loss = Loss(args.type,choice=\"BCE\")#【不加choice，就默认用BCE.可以选择choice=\"L1\"】\n",
    "\n",
    "\n",
    "    for epoch in range(args.epoch_num):\n",
    "        print(\"\\n epoch:\", epoch)\n",
    "        train_epoch(model=auto_encoder, loss=loss, train_loader=train_loader,\n",
    "                    optimizer=optimizer, epoch=epoch, epoch_num=args.epoch_num, arch=args.type)\n",
    "        evaluate_epoch(model=auto_encoder, test_loader=test_loader, loss=loss,\n",
    "                   epoch=epoch, epoch_num=args.epoch_num, arch=args.type)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    matplotlib.use('TkAgg')\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--type\", default=\"CVAE\", choices=[\"AE\", \"VAE\", \"CVAE\"])\n",
    "    parser.add_argument(\"--x_dim\", default=784, type=int)  # 28 x 28 的像素展开为一个一维的行向量，每行代表一个图片\n",
    "    parser.add_argument(\"--latent_size\", default=10, type=int)  # 输出层大小，即服从高斯分布的隐含变量的维度。\n",
    "    parser.add_argument(\"--hidden_size\", default=128, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "    parser.add_argument(\"--epoch_num\", default=128, type=int)\n",
    "    # args = parser.parse_args()\n",
    "    # 调用parser.parse_args()会读取系统参数：sys.argv[]，命令行调用时是正确参数，\n",
    "    # 而在jupyter notebook中调用时，sys.argv的值为ipykrnel_launcher.py：\n",
    "\n",
    "    # args = parser.parse_args(args=[])\n",
    "    \n",
    "    args = parser.parse_known_args()[0]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    args.device = device\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                        level = logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"device: {device} n_gpu: {n_gpu}\")\n",
    "\n",
    "    print(args)\n",
    "    main(args)\n",
    "    # parser.set_defaults(type=\"CVAE\")\n",
    "    # args = parser.parse_args()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('bert_chinese')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53212d6bd219dd71a1dd1974b202da0e24447591239b9cfd3b7797526bde5b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
