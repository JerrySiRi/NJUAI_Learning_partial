{"cells":[{"cell_type":"markdown","metadata":{"id":"3Gf1badl3V1R"},"source":["# Two-Class Support Vector Machine exercise\n","\n","Complete and hand in this completed worksheet with your assignment submission.\n","\n","In this exercise you will:\n","    \n","- Understand the logic of the following code to use SVM for image classification.\n","- Implement a linear SVM by calling functions from scikit-learn module.\n","- Tune parameters of SVM. Analyze the tuned results."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9kgQoiaS4iJS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711608717757,"user_tz":-480,"elapsed":10160,"user":{"displayName":"石睿","userId":"09903880583128013069"}},"outputId":"283104b5-b68e-4959-b16a-18a8b87a0f5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-28 06:51:46--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  52.2MB/s    in 3.3s    \n","\n","2024-03-28 06:51:49 (50.0 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n","cifar-10-batches-py/\n","cifar-10-batches-py/data_batch_4\n","cifar-10-batches-py/readme.html\n","cifar-10-batches-py/test_batch\n","cifar-10-batches-py/data_batch_3\n","cifar-10-batches-py/batches.meta\n","cifar-10-batches-py/data_batch_2\n","cifar-10-batches-py/data_batch_5\n","cifar-10-batches-py/data_batch_1\n"]}],"source":["!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -O cifar-10-python.tar.gz # 下载文件\n","!tar -xzvf cifar-10-python.tar.gz # 解压文件\n","!rm cifar-10-python.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"eU07Yq3U3V1X"},"source":["### (1) Prepare two-class data\n","Prepare CIFAR-10 images. Note that we only use two classes (cat, dog) here for image classification.\n"," - training: 100 images of cats and dogs\n"," - testing: as well as 100 images"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HqmBSJ6Q5HwH","executionInfo":{"status":"ok","timestamp":1711608717757,"user_tz":-480,"elapsed":10,"user":{"displayName":"石睿","userId":"09903880583128013069"}}},"outputs":[],"source":["# define functions for loading CIFAR-10.\n","\n","from six.moves import cPickle as pickle\n","import numpy as np\n","import os\n","import platform\n","\n","def load_pickle(f):\n","    version = platform.python_version_tuple() # python版本是2. or 3.\n","    if version[0] == '2':\n","        return  pickle.load(f)\n","    elif version[0] == '3':\n","        return  pickle.load(f, encoding='latin1')\n","    raise ValueError(\"invalid python version: {}\".format(version))\n","\n","def load_CIFAR_batch(filename):\n","    \"\"\" load single batch of cifar \"\"\"\n","    with open(filename, 'rb') as f:\n","        datadict = load_pickle(f)\n","        X = datadict['data']\n","        Y = datadict['labels']\n","        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n","        # batch操作，把data转换成特定的形状组合就好啦 -- sklearn处理矩阵数据\n","        Y = np.array(Y)\n","        return X, Y\n","\n","def load_CIFAR10(ROOT):\n","    \"\"\" load all of cifar \"\"\"\n","    xs = []\n","    ys = []\n","    for b in range(1,6):\n","        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n","        X, Y = load_CIFAR_batch(f)\n","        xs.append(X)\n","        ys.append(Y)\n","    Xtr = np.concatenate(xs)\n","    Ytr = np.concatenate(ys)\n","    del X, Y\n","    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n","    return Xtr, Ytr, Xte, Yte"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"KRT9brgw3V1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711608730665,"user_tz":-480,"elapsed":12918,"user":{"displayName":"石睿","userId":"09903880583128013069"}},"outputId":"1f920a1f-a116-4627-cfb3-bc9c7279c830"},"outputs":[{"output_type":"stream","name":"stdout","text":["Clear previously loaded data.\n","Training data shape:  (50000, 32, 32, 3)\n","Training labels shape:  (50000,)\n","Test data shape:  (10000, 32, 32, 3)\n","Test labels shape:  (10000,)\n"]}],"source":["# Load the raw CIFAR-10 data.\n","cifar10_dir = './cifar-10-batches-py'\n","\n","# [**********] Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n","try:\n","   del X_train, y_train\n","   del X_test, y_test\n","   print('Clear previously loaded data.')\n","except:\n","   pass\n","\n","X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","# As a sanity check, we print out the size of the training and test data.\n","print('Training data shape: ', X_train.shape)\n","print('Training labels shape: ', y_train.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"c6w0GqhQ3V1Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711608731435,"user_tz":-480,"elapsed":773,"user":{"displayName":"石睿","userId":"09903880583128013069"}},"outputId":"b52563f4-e105-400f-bd21-dd3a810d988b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape:  (200, 32, 32, 3)\n","Training labels shape:  (200,)\n","Test data shape:  (200, 32, 32, 3)\n","Test labels shape:  (200,)\n"]}],"source":["# Extract the two class images. Separate the data into training and validation set.\n","\n","train_smaple_num = 100\n","test_smaple_num = 100\n","\n","# label of 'cat' and 'dog'\n","selected_label = [3, 5]\n","\n","# 【Train】\n","# Re-split the 'cat' and 'dog' samples\n","# 生成一个和y_train形状一样、true or false的矩阵，用来mask\n","cat_mask_train = y_train == selected_label[0]\n","dog_mask_train = y_train == selected_label[1]\n","X2_train_p1 = X_train[cat_mask_train][:train_smaple_num] # cat\n","y2_train_p1 = np.zeros(X2_train_p1.shape[0], dtype=np.int64) # label=0 -- 和sklearn中期望的svm label统一\n","# 【实际上svm应该是1、-1的标注】\n","X2_train_p2 = X_train[dog_mask_train][:train_smaple_num] # dog\n","y2_train_p2 = np.ones(X2_train_p2.shape[0], dtype=np.int64) # label=1\n","X2_train = np.concatenate([X2_train_p1, X2_train_p2], axis=0)\n","y2_train = np.concatenate([y2_train_p1, y2_train_p2], axis=0)\n","\n","# 【Test】\n","cat_mask_test = y_test == selected_label[0]\n","dog_mask_test = y_test == selected_label[1]\n","X2_test_p1 = X_test[cat_mask_test][:test_smaple_num]\n","y2_test_p1 = np.zeros(X2_test_p1.shape[0], dtype=np.int64)\n","X2_test_p2 = X_test[dog_mask_test][:test_smaple_num]\n","y2_test_p2 = np.ones(X2_test_p2.shape[0], dtype=np.int64)\n","X2_test = np.concatenate([X2_test_p1, X2_test_p2], axis=0)\n","y2_test = np.concatenate([y2_test_p1, y2_test_p2], axis=0)\n","\n","# Double check the size of the training and test data.\n","print('Training data shape: ', X2_train.shape)\n","print('Training labels shape: ', y2_train.shape)\n","print('Test data shape: ', X2_test.shape)\n","print('Test labels shape: ', y2_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"IHb69hMm3V1Z"},"source":["### (2) Extract feature vectors\n","We utilized a pretrained CNN to extract the features vectors. Please understand the logic of following code."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"db0zcpzq3V1Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711608737303,"user_tz":-480,"elapsed":5870,"user":{"displayName":"石睿","userId":"09903880583128013069"}},"outputId":"0e6e613e-c620-4e92-dc31-94c53393464b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Training feature shape:  (200, 512)\n","Testing feature shape:  (200, 512)\n"]}],"source":["# Extract the feature vectors of images.\n","# We utilized a pretrained ResNet18 network to extract the layer4 features as the sample features.\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","class ResBase18(nn.Module):\n","    def __init__(self):\n","        super(ResBase18, self).__init__()\n","        # model_resnet18 = models.resnet18(pretrained=True)\n","        # 预训练、含残差连接的神经网络\n","        model_resnet18 = models.resnet18(pretrained=True)\n","        self.conv1 = model_resnet18.conv1\n","        self.bn1 = model_resnet18.bn1\n","        self.relu = model_resnet18.relu\n","        self.maxpool = model_resnet18.maxpool\n","        self.layer1 = model_resnet18.layer1\n","        self.layer2 = model_resnet18.layer2\n","        self.layer3 = model_resnet18.layer3\n","        self.layer4 = model_resnet18.layer4\n","        self.avgpool = model_resnet18.avgpool\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","# define a instance of network, turn to evaluation mode.\n","model = ResBase18()\n","model.eval()\n","\n","# extract features of training and test samples.\n","\"\"\"\n","In PyTorch, the `permute()` function is used to [[perform dimension rearrangement on a tensor.]]\n","It allows for swapping the order of axes or reordering the dimensions of a tensor.\n","\n","In the given code, `permute(0, 3, 1, 2)` is used to change the dimension order of the `X2_train` tensor\n","[[from `(batch_size, height, width, channels)` to `(batch_size, channels, height, width)`]].\n","This is because in PyTorch, the expected input tensor format for convolutional neural network models\n","is usually `(batch_size, channels, height, width)`.\n","By using the `permute()` function to rearrange the dimensions of the tensor,\n","the data is transformed into a tensor format that is suitable for model input.\n","\"\"\"\n","with torch.no_grad():\n","    X2_train_feat = model(torch.FloatTensor(X2_train).permute(0, 3, 1, 2)) # rearrange the dimensions to suit model input\n","    X2_test_feat = model(torch.FloatTensor(X2_test).permute(0, 3, 1, 2))\n","X2_train_feat = X2_train_feat.numpy()\n","X2_test_feat = X2_test_feat.numpy()\n","\n","# Check the dimension of extracted features\n","print('Training feature shape: ', X2_train_feat.shape)\n","print('Testing feature shape: ', X2_test_feat.shape)"]},{"cell_type":"markdown","metadata":{"id":"qp_5Emw9Oj8l"},"source":["### (3) Implement a Linear Support Vector Machine(SVM)\n","Check the documentation at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm to see how to use these functions to train and test a Support Vector Machine(SVM).  \n","**TODO**:\n","- 1) implement a linear SVM;\n","- 2) make predictions with your SVM."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"k2vd7yfY3V1a","executionInfo":{"status":"ok","timestamp":1711608739589,"user_tz":-480,"elapsed":2288,"user":{"displayName":"石睿","userId":"09903880583128013069"}}},"outputs":[],"source":["from sklearn.svm import SVC\n","\n","########################################################################################################\n","# Step 1 TODO:\n","# Training a linear SVM using training set.\n","# You need to write code that trains a SVM. Please refer to the document of sklearn.svm.\n","########################################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Create a svm instance\n","svc = SVC(kernel=\"linear\")\n","\n","# Train the svm instance svc with the training set samples 'X2_train_feat' and labels 'y2_train' as input\n","trained_svm = svc.fit(X2_train_feat, y2_train)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","\n","\n","\n","\n","########################################################################################################\n","# Step 2 TODO:\n","# Using the trained SVM to predict the classification results of validation set.\n","# You need to write code that test the SVM you implemented above.\n","# Again you may refer to the document to see if any functions are already defined for prediction.\n","########################################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Test our trained svm instance svc with the test set samples 'X2_test_feat'\n","y2_pred = trained_svm.predict(X2_test_feat)\n","\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Print the predicted outputs and accuracies.\n","# We use precision, recall and f-measure to measure the accuracy of image classification.\n","# To understand the meaning of these metrics, you can refer to\n","# https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html.\n"]},{"cell_type":"markdown","metadata":{"id":"SRdriP6eOj8m"},"source":["#### Tune paramaters and analyze the results\n","**TODO**: Document the parameters you have tried such as the kernel function or the penalty dunction, and write down your analysis."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3p-VRJ48Oj8m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711608759516,"user_tz":-480,"elapsed":19931,"user":{"displayName":"石睿","userId":"09903880583128013069"}},"outputId":"29dcf05d-dc20-4f31-8681-67df1de31925"},"outputs":[{"output_type":"stream","name":"stdout","text":["current parameter: Kernel=linear, C=0.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.53      0.56       100\n","           1       0.57      0.63      0.60       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.58      0.58      0.58       200\n","weighted avg       0.58      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=0.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.53      0.56       100\n","           1       0.57      0.63      0.60       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.58      0.58      0.58       200\n","weighted avg       0.58      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=0.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.57      0.59       100\n","           1       0.60      0.64      0.62       100\n","\n","    accuracy                           0.60       200\n","   macro avg       0.61      0.60      0.60       200\n","weighted avg       0.61      0.60      0.60       200\n","\n","\n","\n","current parameter: Kernel=linear, C=0.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.57      0.59       100\n","           1       0.60      0.64      0.62       100\n","\n","    accuracy                           0.60       200\n","   macro avg       0.61      0.60      0.60       200\n","weighted avg       0.61      0.60      0.60       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.56      0.58       100\n","           1       0.58      0.62      0.60       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.56      0.58       100\n","           1       0.58      0.62      0.60       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.25, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.53      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.25, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.53      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.53      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.53      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.59       200\n","   macro avg       0.59      0.59      0.59       200\n","weighted avg       0.59      0.59      0.59       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=1.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=2.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=2.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=4, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=4, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=6, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=linear, C=6, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.52      0.56       100\n","           1       0.58      0.65      0.61       100\n","\n","    accuracy                           0.58       200\n","   macro avg       0.59      0.58      0.58       200\n","weighted avg       0.59      0.58      0.58       200\n","\n","\n","\n","current parameter: Kernel=poly, C=0.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.17      0.25       100\n","           1       0.49      0.81      0.61       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.48      0.49      0.43       200\n","weighted avg       0.48      0.49      0.43       200\n","\n","\n","\n","current parameter: Kernel=poly, C=0.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.17      0.25       100\n","           1       0.49      0.81      0.61       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.48      0.49      0.43       200\n","weighted avg       0.48      0.49      0.43       200\n","\n","\n","\n","current parameter: Kernel=poly, C=0.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.25      0.33       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.45       200\n","weighted avg       0.48      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=0.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.25      0.33       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.45       200\n","weighted avg       0.48      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.24      0.32       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.47      0.48      0.45       200\n","weighted avg       0.47      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.24      0.32       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.47      0.48      0.45       200\n","weighted avg       0.47      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.25, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.25      0.33       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.45       200\n","weighted avg       0.48      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.25, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.25      0.33       100\n","           1       0.49      0.72      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.45       200\n","weighted avg       0.48      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.25      0.32       100\n","           1       0.49      0.71      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.47      0.48      0.45       200\n","weighted avg       0.47      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.25      0.32       100\n","           1       0.49      0.71      0.58       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.47      0.48      0.45       200\n","weighted avg       0.47      0.48      0.45       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.27      0.34       100\n","           1       0.49      0.69      0.57       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.46       200\n","weighted avg       0.48      0.48      0.46       200\n","\n","\n","\n","current parameter: Kernel=poly, C=1.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.27      0.34       100\n","           1       0.49      0.69      0.57       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.46       200\n","weighted avg       0.48      0.48      0.46       200\n","\n","\n","\n","current parameter: Kernel=poly, C=2.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.31      0.38       100\n","           1       0.49      0.67      0.57       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.49      0.49      0.47       200\n","weighted avg       0.49      0.49      0.47       200\n","\n","\n","\n","current parameter: Kernel=poly, C=2.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.31      0.38       100\n","           1       0.49      0.67      0.57       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.49      0.49      0.47       200\n","weighted avg       0.49      0.49      0.47       200\n","\n","\n","\n","current parameter: Kernel=poly, C=4, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.38      0.44       100\n","           1       0.52      0.67      0.59       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.51       200\n","weighted avg       0.53      0.53      0.51       200\n","\n","\n","\n","current parameter: Kernel=poly, C=4, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.38      0.44       100\n","           1       0.52      0.67      0.59       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.51       200\n","weighted avg       0.53      0.53      0.51       200\n","\n","\n","\n","current parameter: Kernel=poly, C=6, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.42      0.47       100\n","           1       0.52      0.64      0.58       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.52       200\n","weighted avg       0.53      0.53      0.52       200\n","\n","\n","\n","current parameter: Kernel=poly, C=6, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.42      0.47       100\n","           1       0.52      0.64      0.58       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.52       200\n","weighted avg       0.53      0.53      0.52       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=0.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.34      0.39       100\n","           1       0.47      0.59      0.52       100\n","\n","    accuracy                           0.47       200\n","   macro avg       0.46      0.46      0.46       200\n","weighted avg       0.46      0.47      0.46       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=0.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.34      0.39       100\n","           1       0.47      0.59      0.52       100\n","\n","    accuracy                           0.47       200\n","   macro avg       0.46      0.46      0.46       200\n","weighted avg       0.46      0.47      0.46       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=0.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.39      0.43       100\n","           1       0.49      0.58      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=0.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.39      0.43       100\n","           1       0.49      0.58      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.39      0.43       100\n","           1       0.49      0.58      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.39      0.43       100\n","           1       0.49      0.58      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.25, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.38      0.42       100\n","           1       0.49      0.59      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.25, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.38      0.42       100\n","           1       0.49      0.59      0.53       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.36      0.41       100\n","           1       0.49      0.61      0.54       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.36      0.41       100\n","           1       0.49      0.61      0.54       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.48       200\n","weighted avg       0.48      0.48      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.36      0.41       100\n","           1       0.49      0.62      0.55       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.49      0.49      0.48       200\n","weighted avg       0.49      0.49      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=1.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.36      0.41       100\n","           1       0.49      0.62      0.55       100\n","\n","    accuracy                           0.49       200\n","   macro avg       0.49      0.49      0.48       200\n","weighted avg       0.49      0.49      0.48       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=2.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.36      0.41       100\n","           1       0.48      0.60      0.54       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.47       200\n","weighted avg       0.48      0.48      0.47       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=2.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.36      0.41       100\n","           1       0.48      0.60      0.54       100\n","\n","    accuracy                           0.48       200\n","   macro avg       0.48      0.48      0.47       200\n","weighted avg       0.48      0.48      0.47       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=4, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.46      0.49       100\n","           1       0.52      0.59      0.55       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.52       200\n","weighted avg       0.53      0.53      0.52       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=4, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.46      0.49       100\n","           1       0.52      0.59      0.55       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.52       200\n","weighted avg       0.53      0.53      0.52       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=6, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.48      0.51       100\n","           1       0.53      0.58      0.55       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.53       200\n","weighted avg       0.53      0.53      0.53       200\n","\n","\n","\n","current parameter: Kernel=rbf, C=6, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.48      0.51       100\n","           1       0.53      0.58      0.55       100\n","\n","    accuracy                           0.53       200\n","   macro avg       0.53      0.53      0.53       200\n","weighted avg       0.53      0.53      0.53       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=0.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=0.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=0.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=0.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.25, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.25, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.5, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.5, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.75, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=1.75, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.37      0.44       100\n","           1       0.53      0.70      0.60       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.54      0.53      0.52       200\n","weighted avg       0.54      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=2.0, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.36      0.44       100\n","           1       0.53      0.72      0.61       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.55      0.54      0.52       200\n","weighted avg       0.55      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=2.0, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.36      0.44       100\n","           1       0.53      0.72      0.61       100\n","\n","    accuracy                           0.54       200\n","   macro avg       0.55      0.54      0.52       200\n","weighted avg       0.55      0.54      0.52       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=4, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.38      0.41       100\n","           1       0.45      0.51      0.48       100\n","\n","    accuracy                           0.45       200\n","   macro avg       0.44      0.45      0.44       200\n","weighted avg       0.44      0.45      0.44       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=4, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.38      0.41       100\n","           1       0.45      0.51      0.48       100\n","\n","    accuracy                           0.45       200\n","   macro avg       0.44      0.45      0.44       200\n","weighted avg       0.44      0.45      0.44       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=6, Penalty=l2\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.40      0.42       100\n","           1       0.45      0.49      0.47       100\n","\n","    accuracy                           0.45       200\n","   macro avg       0.44      0.45      0.44       200\n","weighted avg       0.44      0.45      0.44       200\n","\n","\n","\n","current parameter: Kernel=sigmoid, C=6, Penalty=l1\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.40      0.42       100\n","           1       0.45      0.49      0.47       100\n","\n","    accuracy                           0.45       200\n","   macro avg       0.44      0.45      0.44       200\n","weighted avg       0.44      0.45      0.44       200\n","\n","\n","\n"]}],"source":["\n","########################################################################################################\n","# Step 3 TODO:                                                                                         #\n","# You may tune parameters like kernels and penality functions to improve your testing results.\n","# Then, you need to write down what parameters you have tried and the analysis of results.\n","# Note that you can write your analysis in the next block or in the writing assignment.\n","########################################################################################################\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","kernel_list = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n","C_list = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 4, 6]\n","penalty_list = [\"l2\", \"l1\"]\n","\n","for cur_kernel in kernel_list:\n","  for cur_C in C_list:\n","    for cur_penalty in penalty_list:\n","      print(\"current parameter: Kernel={0}, C={1}, Penalty={2}\".format(cur_kernel,cur_C,cur_penalty))\n","      cur_svc = SVC(kernel=cur_kernel, C=cur_C, cache_size = 500)\n","      trained_svm = cur_svc.fit(X2_train_feat, y2_train)\n","      y2_pred = trained_svm.predict(X2_test_feat)\n","      print(classification_report(y2_test,y2_pred))\n","      print(\"\\n\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6FzIwVbKOj8m"},"source":["**Analysis**:\n","1. **Experiment result**:\n","\n","Best parameters: Kernel=linear, C=0.75, Penalty=l2/l1 (regularization l1 and l2 have the same metics value.)\n","\n","|  | precision | recall | f1-score | support |\n","| --- | --- | --- | | |\n","| 0 | 0.61 | 0.57 |0.59|100|\n","| 1 | 0.60 | 0.64 |0.62|100|\n","| accuracy | - | - |0.60|200|\n","| macro avg | 0.61 | 0.60 |0.60|200|\n","| weighted avg | 0.61 | 0.60 |0.60|200|\n","\n","\n","2. **Analysis**:\n","- Initial feature is likely linear separable space? (probably)\n","- Given abundant computing time and resources, SVM possesses a strong fitting capacity. However, in this experiment, we encountered not a perfect result. There are some resonable analysis below:\n","\n","As we known, SVM fits a linear decisionn boundary in initial vector space.\n","Meanwhile, it is proved that when we map initial vector space to a high dimentional space (dimension might be infinite), mapped data is linearly separable for sure.\n","\n","\n","Moreover, The kernel function and the mapping function have a one-to-one correspondence, and the feature space induced by a kernel function is called a reproducing Hilbert space.\n","\n","That we are constricted by finite computing resources and time could be significant reason that we could not attempt lots of high dimention vector space (the same as lots of mapping or kernel function) to test whether mapped data in this space is linearly separable, generating a not perfect experiment reslt.\n","\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1qn_DEJ_HhyAkDclcguOwh5RMwul28c5P","timestamp":1711521035646}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}