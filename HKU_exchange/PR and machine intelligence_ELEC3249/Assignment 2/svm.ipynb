{"cells":[{"cell_type":"markdown","metadata":{"id":"3Gf1badl3V1R"},"source":["# Two-Class Support Vector Machine exercise\n","\n","Complete and hand in this completed worksheet with your assignment submission.\n","\n","In this exercise you will:\n","    \n","- Understand the logic of the following code to use SVM for image classification.\n","- Implement a linear SVM by calling functions from scikit-learn module.\n","- Tune parameters of SVM. Analyze the tuned results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kgQoiaS4iJS"},"outputs":[],"source":["!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -O cifar-10-python.tar.gz\n","!tar -xzvf cifar-10-python.tar.gz\n","!rm cifar-10-python.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"eU07Yq3U3V1X"},"source":["### Prepare two-class data\n","Prepare CIFAR-10 images. Note that we only use two classes (cat, dog) here for image classification."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqmBSJ6Q5HwH"},"outputs":[],"source":["# define functions for loading CIFAR-10.\n","\n","from six.moves import cPickle as pickle\n","import numpy as np\n","import os\n","import platform\n","\n","def load_pickle(f):\n","    version = platform.python_version_tuple()\n","    if version[0] == '2':\n","        return  pickle.load(f)\n","    elif version[0] == '3':\n","        return  pickle.load(f, encoding='latin1')\n","    raise ValueError(\"invalid python version: {}\".format(version))\n","\n","def load_CIFAR_batch(filename):\n","    \"\"\" load single batch of cifar \"\"\"\n","    with open(filename, 'rb') as f:\n","        datadict = load_pickle(f)\n","        X = datadict['data']\n","        Y = datadict['labels']\n","        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n","        Y = np.array(Y)\n","        return X, Y\n","\n","def load_CIFAR10(ROOT):\n","    \"\"\" load all of cifar \"\"\"\n","    xs = []\n","    ys = []\n","    for b in range(1,6):\n","        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n","        X, Y = load_CIFAR_batch(f)\n","        xs.append(X)\n","        ys.append(Y)\n","    Xtr = np.concatenate(xs)\n","    Ytr = np.concatenate(ys)\n","    del X, Y\n","    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n","    return Xtr, Ytr, Xte, Yte"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRT9brgw3V1X"},"outputs":[],"source":["# Load the raw CIFAR-10 data.\n","cifar10_dir = './cifar-10-batches-py'\n","\n","# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n","try:\n","   del X_train, y_train\n","   del X_test, y_test\n","   print('Clear previously loaded data.')\n","except:\n","   pass\n","\n","X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","# As a sanity check, we print out the size of the training and test data.\n","print('Training data shape: ', X_train.shape)\n","print('Training labels shape: ', y_train.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6w0GqhQ3V1Y"},"outputs":[],"source":["# Extract the two class images. Separate the data into training and validation set.\n","\n","train_smaple_num = 100\n","test_smaple_num = 100\n","\n","# label of 'cat' and 'dog'\n","selected_label = [3, 5]\n","\n","# Re-split the 'cat' and 'dog' samples\n","cat_mask_train = y_train == selected_label[0]\n","dog_mask_train = y_train == selected_label[1]\n","\n","X2_train_p1 = X_train[cat_mask_train][:train_smaple_num]\n","y2_train_p1 = np.zeros(X2_train_p1.shape[0], dtype=np.int64)\n","X2_train_p2 = X_train[dog_mask_train][:train_smaple_num]\n","y2_train_p2 = np.ones(X2_train_p2.shape[0], dtype=np.int64)\n","X2_train = np.concatenate([X2_train_p1, X2_train_p2], axis=0)\n","y2_train = np.concatenate([y2_train_p1, y2_train_p2], axis=0)\n","\n","cat_mask_test = y_test == selected_label[0]\n","dog_mask_test = y_test == selected_label[1]\n","\n","X2_test_p1 = X_test[cat_mask_test][:test_smaple_num]\n","y2_test_p1 = np.zeros(X2_test_p1.shape[0], dtype=np.int64)\n","X2_test_p2 = X_test[dog_mask_test][:test_smaple_num]\n","y2_test_p2 = np.ones(X2_test_p2.shape[0], dtype=np.int64)\n","X2_test = np.concatenate([X2_test_p1, X2_test_p2], axis=0)\n","y2_test = np.concatenate([y2_test_p1, y2_test_p2], axis=0)\n","\n","# Double check the size of the training and test data.\n","print('Training data shape: ', X2_train.shape)\n","print('Training labels shape: ', y2_train.shape)\n","print('Test data shape: ', X2_test.shape)\n","print('Test labels shape: ', y2_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"IHb69hMm3V1Z"},"source":["### Extract feature vectors\n","We utilized a pretrained CNN to extract the features vectors. Please understand the logic of following code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"db0zcpzq3V1Z"},"outputs":[],"source":["# Extract the feature vectors of images.\n","# We utilized a pretrained ResNet18 network to extract the layer4 features as the sample features.\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","class ResBase18(nn.Module):\n","    def __init__(self):\n","        super(ResBase18, self).__init__()\n","        # model_resnet18 = models.resnet18(pretrained=True)\n","        model_resnet18 = models.resnet18(pretrained=True)\n","        self.conv1 = model_resnet18.conv1\n","        self.bn1 = model_resnet18.bn1\n","        self.relu = model_resnet18.relu\n","        self.maxpool = model_resnet18.maxpool\n","        self.layer1 = model_resnet18.layer1\n","        self.layer2 = model_resnet18.layer2\n","        self.layer3 = model_resnet18.layer3\n","        self.layer4 = model_resnet18.layer4\n","        self.avgpool = model_resnet18.avgpool\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","# define a instance of network, turn to evaluation mode.\n","model = ResBase18()\n","model.eval()\n","\n","# extract features of training and test samples.\n","with torch.no_grad():\n","    X2_train_feat = model(torch.FloatTensor(X2_train).permute(0, 3, 1, 2))\n","    X2_test_feat = model(torch.FloatTensor(X2_test).permute(0, 3, 1, 2))\n","X2_train_feat = X2_train_feat.numpy()\n","X2_test_feat = X2_test_feat.numpy()\n","\n","# Check the dimension of extracted features\n","print('Training feature shape: ', X2_train_feat.shape)\n","print('Testing feature shape: ', X2_test_feat.shape)"]},{"cell_type":"markdown","metadata":{"id":"qp_5Emw9Oj8l"},"source":["### Implement a Linear Support Vector Machine(SVM)\n","Check the documentation at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm to see how to use these functions to train and test a Support Vector Machine(SVM).  \n","**TODO**: 1) implement a linear SVM; 2) make predictions with your SVM."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2vd7yfY3V1a"},"outputs":[],"source":["from sklearn import svm\n","\n","########################################################################################################\n","# Step 1 TODO:                                                                                         #\n","# Training a linear SVM using training set.                                                            #\n","# You need to write code that trains a SVM. Please refer to the document of sklearn.svm.               #\n","########################################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Create a svm instance\n","svc =\n","\n","# Train the svm instance svc with the training set samples 'X2_train_feat' and labels 'y2_train' as input\n","\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","\n","########################################################################################################\n","# Step 2 TODO:                                                                                         #\n","# Using the trained SVM to predict the classification results of validation set.                       #\n","# You need to write code that test the SVM you implemented above.                                      #\n","# Again you may refer to the document to see if any functions are already defined for prediction.      #\n","########################################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Test our trained svm instance svc with the test set samples 'X2_test_feat'\n","y2_pred =\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Print the predicted outputs and accuracies.\n","# We use precision, recall and f-measure to measure the accuracy of image classification.\n","# To understand the meaning of these metrics, you can refer to\n","# https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html.\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(classification_report(y2_test,y2_pred))"]},{"cell_type":"markdown","metadata":{"id":"SRdriP6eOj8m"},"source":["#### Tune paramaters and analyze the results\n","**TODO**: Document the parameters you have tried such as the kernel function or the penalty dunction, and write down your analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3p-VRJ48Oj8m"},"outputs":[],"source":["\n","########################################################################################################\n","# Step 3 TODO:                                                                                         #\n","# You may tune parameters like kernels and penality functions to improve your testing results.         #\n","# Then, you need to write down what parameters you have tried and the analysis of results.             #\n","# Note that you can write your analysis in the next block or in the writing assignment.                #\n","########################################################################################################\n"]},{"cell_type":"markdown","metadata":{"id":"6FzIwVbKOj8m"},"source":["Analysis:\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1qn_DEJ_HhyAkDclcguOwh5RMwul28c5P","timestamp":1711521035646}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}