{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI4A-T0z5AU6"
      },
      "source": [
        "# Assignment 1\n",
        "You should submit the **UniversityNumber.ipynb** file and your final prediction file **UniversityNumber.test.txt** to moodle. Make sure your code does not use your local files and that the results are reproducible. Before submitting, please **1. clean all outputs and 2. run all cells in your notebook and keep all running logs** so that we can check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEomoMzH5Nf6"
      },
      "source": [
        "# 1 $n$-gram Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsSAtTqt7Q8a"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/lm\n",
        "!wget -O data/lm/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/lm/train.txt\n",
        "!wget -O data/lm/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/lm/dev.txt\n",
        "!wget -O data/lm/test.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/lm/test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ElrINWW7oF7"
      },
      "source": [
        "## 1.1 Building vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eawcuVV19kZm"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "q-rNT_QL8Dvt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary size is 26601\n",
            "('officer|police', 34)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "description: Building Vocabulary\n",
        "\"\"\"\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "V_uni = defaultdict(int) # set default number 0 to all tokens\n",
        "V_bi = defaultdict(int) # set default number 0 to all tokens\n",
        "\n",
        "def preprocess(vo_dict, wh_filter=1):\n",
        "    voca_list = list(vo_dict.items())\n",
        "    # TODO: use np.where to implement filter, instead of for\n",
        "    if wh_filter == 1:\n",
        "        voca_key, voca_values = zip(*voca_list)\n",
        "        index = np.where(np.array(voca_values)>=3)\n",
        "        valid_array = np.array(voca_list)[index]\n",
        "        valid_list = list(valid_array)\n",
        "    else:\n",
        "        valid_list = voca_list\n",
        "    valid_list.append(('<UNK>', 0))\n",
        "    valid_list.append(('<START>', 0))\n",
        "    valid_list.append(('<END>', 0))\n",
        "    return valid_list\n",
        "\n",
        "\n",
        "with open(\"./data/lm/train.txt\",'r+',encoding='utf-8') as f:\n",
        "    for line in f.readlines():\n",
        "        curline = line.strip().split(\" \") # use function:strip to drop \"\\n\"\n",
        "        for item in curline: # 1.compute c(w)\n",
        "            V_uni[item] += 1\n",
        "        for index in range(0, len(curline)):# 2.compute c(w,u)\n",
        "            if index != len(curline)-1:\n",
        "                string = curline[index+1] + \"|\" + curline[index] \n",
        "                # contaminate two string, with shape \"new|old\"\n",
        "                V_bi[string] += 1\n",
        "\n",
        "\n",
        "# c(w) -- convert Vocabulary into different formats(list\\ndarray\\dict)\n",
        "uni_list = preprocess(V_uni, wh_filter=1)\n",
        "uni_array = np.array(uni_list)\n",
        "uni_dict = dict(uni_list)\n",
        "print(\"vocabulary size is\",len(uni_list))\n",
        "\n",
        "# c(w,u) -- adjacent tokens pair\n",
        "bi_list = preprocess(V_bi, wh_filter=0)\n",
        "bi_array = np.array(bi_list)\n",
        "bi_dict = dict(bi_list)\n",
        "#print(bi_list[3])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7oBATsX8uHb"
      },
      "source": [
        "### Discussion：\n",
        "discuss the number of parameters of n-gram models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU6VpAkS9odh"
      },
      "source": [
        "TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2BGUig8TqH"
      },
      "source": [
        "## 1.2 $n$-gram Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyANMPe9ad_"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ACSfNZGE8Yw2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "description: build bigram and unigram language models and\n",
        "report their perplexity on the training set, and dev set\n",
        "\"\"\"\n",
        "import copy\n",
        "\n",
        "N = 26601 # vocabulary size\n",
        "\n",
        "class N_Gram():\n",
        "    def __init__(self, indicator, smoothing=None, k=None) -> None:\n",
        "        self.indicator = indicator # which model: unigram or bigram\n",
        "        self.smoothing = smoothing # which smoothing method to be selected\n",
        "        self.k = k # add-k smoothing\n",
        "\n",
        "    def construct(self):\n",
        "        if self.smoothing == None:\n",
        "            return self.no_smoothing() # return a dictionary of unigram or bigram \n",
        "        elif self.smoothing == \"add-one\":\n",
        "            pass\n",
        "        elif self.smoothing == \"add-k\":\n",
        "            pass\n",
        "        \n",
        "    def no_smoothing(self):\n",
        "\n",
        "        if self.indicator == \"unigram\": # model: {token: probability}\n",
        "            self.uni_model = copy.deepcopy(uni_dict) # frequency\n",
        "            for (token, fre) in uni_dict.items():\n",
        "                pro = fre / N\n",
        "                self.uni_model[token] = pro # \"probability\"\n",
        "            return self.uni_model\n",
        "        elif self.indicator == \"bigram\": # model: {token+1|token: probability}\n",
        "            self.bi_model = copy.deepcopy(bi_dict)\n",
        "            for (token, fre) in bi_dict.items():\n",
        "                sep_index = token.find('|')\n",
        "                last_token = token[sep_index+1 : ]\n",
        "                pro = fre / uni_dict[last_token]\n",
        "                self.bi_model[token] = pro\n",
        "            return self.bi_model\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWC56a19TbY"
      },
      "source": [
        "### Discussion： \n",
        "If you encounter any problems, please analyze them and explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM4gcgL--Ylh"
      },
      "source": [
        "TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuLL8CH1Ua-3"
      },
      "source": [
        "## 1.3 Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7mWQhaCUixZ"
      },
      "source": [
        "### 1.3.1 Add-one (Laplace) smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbbHxLDmVrz6"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93_yLu9dVr0C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y1WOQtsVr0D"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTknh9pRVr0D"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTC0qJE8VVha"
      },
      "source": [
        "#### 1.3.2 Add-k smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3itGMOOVuNg"
      },
      "source": [
        "##### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhcuJWo7VuNg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzpU_p6CVuNg"
      },
      "source": [
        "##### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIOUpNXYVuNh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJFWxsN-Uj0Y"
      },
      "source": [
        "### 1.3.3 Linear Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk11EpboWVCH"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4N_XuN6WVCQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8v2P36WVCQ"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGkf6IV0WVCQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvgTZcNFVato"
      },
      "source": [
        "##### 1.3.4 Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnXu98hWcfu"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKo4ZLASWcfu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2 Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13868\\3803626181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwv_from_bin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mwv_from_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_embedding_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13868\\3803626181.py\u001b[0m in \u001b[0;36mload_embedding_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mwv_from_bin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAll\u001b[0m \u001b[1;36m400000\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[0mlengh\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mwv_from_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"glove-wiki-gigaword-200\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded vocab size %i\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_from_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
          ]
        }
      ],
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each lengh 50\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "    print(\"Loaded vocab size %i\" % len(list(wv_from_bin.index_to_key)))\n",
        "    return wv_from_bin\n",
        "\n",
        "wv_from_bin = load_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Find most similar word\n",
        "Use cosine similarity to find the most similar word to each of these words. Report the most similar word and its cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Finding Analogies\n",
        "Use vector addition and subtraction to compute target vectors for the analogies below. After computing each target vector, find the top three candidates by cosine similarity. Report the candidates and their similarities to the target vector.\n",
        "\n",
        "- dog : puppy :: cat : ?:\n",
        "- speak : speaker :: sing : ?:\n",
        "- France : French :: England : ?:\n",
        "- France : wine :: England : ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p data/classification\n",
        "!wget -O data/classification/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/classification/train.txt\n",
        "!wget -O data/classification/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/classification/dev.txt\n",
        "!wget -O data/classification/test-blind.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A1/data/classification/test-blind.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unigram Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bigram Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GloVe Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the performance of three types of features on dev set. Report the weighted average precision, recall and F1-score for each feature set.\n",
        "\n",
        "| Feature | precision | recall | F1-score |\n",
        "| ----------- | --------- | ------ | -------- |\n",
        "| unigram     |           |        |          |\n",
        "| bigram      |           |        |          |\n",
        "| GloVe       |           |        |          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Better Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.1 ('bert_chinese')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "53212d6bd219dd71a1dd1974b202da0e24447591239b9cfd3b7797526bde5b81"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
