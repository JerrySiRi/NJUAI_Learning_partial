{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COMP3361 Part 1: Building a Transformer Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: You should finish your code solution of Part 1 & 2 with A2p12.tgz. For Q2 & Q3, you should include your writeup in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COMP3361 Part 3: Generation with Large Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model and tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will use [CodeLlama-7B](https://huggingface.co/codellama/CodeLlama-7b-hf) as the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU4clXj7uta9",
        "outputId": "075fc372-6e45-4918-f07a-679b12cadb24"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1cF8N6xt5J7"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "import json\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q6zTg8BuFCX"
      },
      "outputs": [],
      "source": [
        "class LLM(object):\n",
        "    def __init__(self, model_name=\"codellama/CodeLlama-7b-hf\"):\n",
        "        pass\n",
        "\n",
        "    def generate(self, prompts: List[str], **kwargs) -> List[str]:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "53d73c31b8e4471d8db727a476fc4c99",
            "05e75900a7a84a5b9facb05b6ab2375c",
            "1d63cdf830774efbb632c631d81ba898",
            "710166b01a344084b467b3343326899d",
            "27dd83f2eeb64e33ab3ec4945e79f0f7",
            "a93b8acb56144e90ad4b62c39ba82071",
            "0770d14b807c41fe950bf003c2d2b4f5",
            "26ec45c0e68c49bc833026436f776989",
            "c38c4a34c78f4f3193fc093940b5b8f8",
            "b9b4c9f55c7a45e794ac0582c2e00256",
            "861eccde5c924cfda51ec0dbd93d73c2"
          ]
        },
        "id": "59OjAXaewjpt",
        "outputId": "279e9bed-f7b3-4629-8735-e7f2fe476dc2"
      },
      "outputs": [],
      "source": [
        "llm = LLM()\n",
        "\n",
        "llm.generate([\"A list of colors: red, blue\", \"Portugal is\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC_-chU1uHqL"
      },
      "outputs": [],
      "source": [
        "class Evaluator(ABC):\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_data(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def build_prompts(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def postprocess_output(self, output: str) -> str:\n",
        "        pass\n",
        "\n",
        "    def generate_completions(self, prompts: List[str], batch_size=4, **kwargs) -> List[str]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def evaluate(self, evalset_file, batch_size=4, save_dir=\"outputs\", max_new_tokens=128, **kwargs):\n",
        "        dataset = self.load_data(evalset_file)\n",
        "        prompts = self.build_prompts(dataset)\n",
        "        outputs = self.generate_completions(prompts, batch_size=batch_size, max_new_tokens=max_new_tokens, **kwargs)\n",
        "\n",
        "        predictions = []\n",
        "        for i, (example, prompt, output) in enumerate(zip(dataset, prompts, outputs)):\n",
        "            prediction = {\n",
        "                \"task_id\": example.get(\"task_id\", f\"task_{i}\"),\n",
        "                \"prompt\": prompt,\n",
        "                \"completion\": self.postprocess_output(output)\n",
        "            }\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        # Save predictions to file\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        prediction_save_path = os.path.join(save_dir, f\"{type(self).__name__}_predictions.jsonl\")\n",
        "        with open(prediction_save_path, \"w\") as fout:\n",
        "            for pred in predictions:\n",
        "                fout.write(json.dumps(pred) + \"\\n\")\n",
        "\n",
        "        # Calculate metrics and print results\n",
        "        results = self.calculate_metrics(predictions, dataset)\n",
        "        print(f\"Results for {type(self).__name__}: {results}\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def calculate_metrics(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zero-shot Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEw3OvExutT9",
        "outputId": "900e3643-2ba2-464a-bf79-4ed32dd76094"
      },
      "outputs": [],
      "source": [
        "!mkdir -p human_eval\n",
        "!wget -O human_eval/__init__.py https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A2/human_eval/__init__.py\n",
        "!wget -O human_eval/data.py human_eval https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A2/human_eval/data.py\n",
        "!wget -O human_eval/evaluation.py https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A2/human_eval/evaluation.py\n",
        "!wget -O human_eval/execution.py human_eval https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A2/human_eval/execution.py\n",
        "\n",
        "!mkdir -p data/humaneval\n",
        "!wget -O data/humaneval/HumanEval.jsonl.gz https://github.com/openai/human-eval/raw/master/data/HumanEval.jsonl.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xtsnKpjuKCI"
      },
      "outputs": [],
      "source": [
        "from human_eval.data import read_problems\n",
        "from human_eval.evaluation import evaluate_functional_correctness\n",
        "\n",
        "class HumanEvalEvaluator(Evaluator):\n",
        "    def load_data(self, evalset_file=\"data/humaneval/HumanEval.jsonl.gz\") -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Load the humaneval dataset\n",
        "        :param evalset_file: path to the humaneval dataset file\n",
        "        :return: list of examples\n",
        "        \"\"\"\n",
        "        return list(read_problems(evalset_file).values())\n",
        "\n",
        "    def build_prompts(self, dataset) -> List[str]:\n",
        "        \"\"\"\n",
        "        Build zero-shot prompts from the humaneval dataset.\n",
        "        \"\"\"\n",
        "        prompts = [example[\"prompt\"] for example in dataset]\n",
        "        return prompts\n",
        "\n",
        "    def postprocess_output(self, output: str) -> str:\n",
        "        stop_sequences=[\"\\nclass\", \"\\ndef\", \"\\n#\", \"\\nif\", \"\\nprint\"]\n",
        "        \n",
        "        raise NotImplementedError\n",
        "\n",
        "    def calculate_metrics(self, predictions, dataset):\n",
        "        pass_at_k_results = evaluate_functional_correctness(\n",
        "            sample_file=os.path.join(\"outputs\", f\"{type(self).__name__}_predictions.jsonl\"),\n",
        "            k=[1],\n",
        "            problems={example[\"task_id\"]: example for example in dataset},\n",
        "            n_workers=64\n",
        "        )\n",
        "        return pass_at_k_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "J91pEUb_uXgB",
        "outputId": "004bf29f-4b27-4584-ce8d-8b31a89d99f2"
      },
      "outputs": [],
      "source": [
        "human_eval_evaluator = HumanEvalEvaluator(llm)\n",
        "human_eval_evaluator.evaluate(batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Few-shot Math Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AGOtyjcuPHJ"
      },
      "outputs": [],
      "source": [
        "GSM_EXAMPLARS = [\n",
        "    {\n",
        "        \"question\": \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\",\n",
        "        \"cot_answer\": \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. So the answer is 6.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\\"\\\"\\\"\\n    trees_initial = 15\\n    trees_after = 21\\n    trees_added = trees_after - trees_initial\\n    result = trees_added\\n    return result\",\n",
        "        \"short_answer\": \"6\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\",\n",
        "        \"cot_answer\": \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. So the answer is 5.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\\"\\\"\\\"\\n    cars_initial = 3\\n    cars_arrived = 2\\n    total_cars = cars_initial + cars_arrived\\n    result = total_cars\\n    return result\",\n",
        "        \"short_answer\": \"5\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\",\n",
        "        \"cot_answer\": \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. So the answer is 39.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\\"\\\"\\\"\\n    leah_chocolates = 32\\n    sister_chocolates = 42\\n    total_chocolates = leah_chocolates + sister_chocolates\\n    chocolates_eaten = 35\\n    chocolates_left = total_chocolates - chocolates_eaten\\n    result = chocolates_left\\n    return result\",\n",
        "        \"short_answer\": \"39\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\",\n",
        "        \"cot_answer\": \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. So the answer is 8.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\\"\\\"\\\"\\n    jason_lollipops_initial = 20\\n    jason_lollipops_after = 12\\n    denny_lollipops = jason_lollipops_initial - jason_lollipops_after\\n    result = denny_lollipops\\n    return result\",\n",
        "        \"short_answer\": \"8\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\",\n",
        "        \"cot_answer\": \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. So the answer is 9.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\\"\\\"\\\"\\n    toys_initial = 5\\n    mom_toys = 2\\n    dad_toys = 2\\n    total_received = mom_toys + dad_toys\\n    total_toys = toys_initial + total_received\\n    result = total_toys\\n    return result\",\n",
        "        \"short_answer\": \"9\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\",\n",
        "        \"cot_answer\": \"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. So the answer is 29.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\\"\\\"\\\"\\n    toys_initial = 5\\n    mom_toys = 2\\n    dad_toys = 2\\n    total_received = mom_toys + dad_toys\\n    total_toys = toys_initial + total_received\\n    result = total_toys\\n    return result\",\n",
        "        \"short_answer\": \"29\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\",\n",
        "        \"cot_answer\": \"Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. So the answer is 33.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\\"\\\"\\\"\\n    golf_balls_initial = 58\\n    golf_balls_lost_tuesday = 23\\n    golf_balls_lost_wednesday = 2\\n    golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday - golf_balls_lost_wednesday\\n    result = golf_balls_left\\n    return result\",\n",
        "        \"short_answer\": \"33\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\",\n",
        "        \"cot_answer\": \"Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8. So the answer is 8.\",\n",
        "        \"pot_answer\": \"def solution():\\n    \\\"\\\"\\\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\\"\\\"\\\"\\n    money_initial = 23\\n    bagels = 5\\n    bagel_cost = 3\\n    money_spent = bagels * bagel_cost\\n    money_left = money_initial - money_spent\\n    result = money_left\\n    return result\",\n",
        "        \"short_answer\": \"8\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbAdW1gMuR0t"
      },
      "outputs": [],
      "source": [
        "class GSM8KEvaluator(Evaluator):\n",
        "    def load_data(self, evalset_file=\"gsm8k\") -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Load the GSM8K dataset https://huggingface.co/datasets/gsm8k with Huggingface datasets library\n",
        "        Load the first 100 examples from the test split in main subset.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build_prompts(self, dataset, n_shot=8, demos=GSM_EXAMPLARS):\n",
        "        \"\"\"\n",
        "        Build few-shot prompts from the GSM8K dataset. Use \n",
        "        :param dataset: list of examples\n",
        "        :param n_shot: number of examples to use for few-shot learning\n",
        "        :param demos: list of demonstrator examples\n",
        "        :return: list of prompts\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def postprocess_output(self, output: str) -> str:\n",
        "        \"\"\"\n",
        "        Postprocess the output from the language model.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def calculate_metrics(self, predictions, dataset):\n",
        "        \"\"\"\n",
        "        Calculate metrics for the GSM8K dataset\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AngLuranuVVo"
      },
      "outputs": [],
      "source": [
        "gsm8k_evaluator = GSM8KEvaluator(llm)\n",
        "gsm8k_evaluator.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Few-shot Chain-of Thought Math Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class GSM8KCoTEvaluator(GSM8KEvaluator):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gsm8k_cot_evaluator = GSM8KCoTEvaluator(llm)\n",
        "gsm8k_cot_evaluator.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Few-shot Program-of Thought Math Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install timeout-decorator Pebble\n",
        "!wget -O python_executor.py https://raw.githubusercontent.com/ranpox/comp3361-spring2024/main/assignments/A2/python_executor.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from python_executor import PythonExecutor\n",
        "executor = PythonExecutor(get_answer_expr='solution()')\n",
        "\n",
        "codes = [\n",
        "    \"def solution():\\n    return 1 + 1\",\n",
        "    \"def solution():\\n    return 2 * 2\",\n",
        "]\n",
        "\n",
        "predictions = []\n",
        "runtime_errors = []\n",
        "for pred, err in executor.batch_apply(codes):\n",
        "    predictions.append(str(pred))\n",
        "    runtime_errors.append(str(err['exec_info']).strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GSM8KPoTEvaluator(Evaluator):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|                    | GSM8K |\n",
        "|--------------------|-------|\n",
        "| Direct Prompting   |       |\n",
        "| Chain-of-Thought   |       |\n",
        "| Program-of-Thought |       |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e75900a7a84a5b9facb05b6ab2375c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a93b8acb56144e90ad4b62c39ba82071",
            "placeholder": "​",
            "style": "IPY_MODEL_0770d14b807c41fe950bf003c2d2b4f5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0770d14b807c41fe950bf003c2d2b4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d63cdf830774efbb632c631d81ba898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ec45c0e68c49bc833026436f776989",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c38c4a34c78f4f3193fc093940b5b8f8",
            "value": 2
          }
        },
        "26ec45c0e68c49bc833026436f776989": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27dd83f2eeb64e33ab3ec4945e79f0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d73c31b8e4471d8db727a476fc4c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05e75900a7a84a5b9facb05b6ab2375c",
              "IPY_MODEL_1d63cdf830774efbb632c631d81ba898",
              "IPY_MODEL_710166b01a344084b467b3343326899d"
            ],
            "layout": "IPY_MODEL_27dd83f2eeb64e33ab3ec4945e79f0f7"
          }
        },
        "710166b01a344084b467b3343326899d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b4c9f55c7a45e794ac0582c2e00256",
            "placeholder": "​",
            "style": "IPY_MODEL_861eccde5c924cfda51ec0dbd93d73c2",
            "value": " 2/2 [01:17&lt;00:00, 35.27s/it]"
          }
        },
        "861eccde5c924cfda51ec0dbd93d73c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a93b8acb56144e90ad4b62c39ba82071": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b4c9f55c7a45e794ac0582c2e00256": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38c4a34c78f4f3193fc093940b5b8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
