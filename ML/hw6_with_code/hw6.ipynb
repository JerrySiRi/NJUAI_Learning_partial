{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 of Machine Learning\n",
    "\n",
    "## PPG-DaLiA reference:\n",
    "\n",
    "- https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA\n",
    "- https://archive.ics.uci.edu/ml/machine-learning-databases/00495/readme.pdf\n",
    "\n",
    "## Scikit-learn reference:\n",
    "\n",
    "- https://scikit-learn.org/stable/index.html\n",
    "\n",
    "## PyTorch reference:\n",
    "\n",
    "- https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file with pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "test_df = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1    [10pts] Dataset Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 [2pts] Output the features in training and test data and find the difference\n",
    "\n",
    "# Fill in None in the following code.\n",
    "\n",
    "print(\"Training data:\")\n",
    "train_features = None\n",
    "for fea in train_features:\n",
    "    print(f\"Feature: {fea}, Type: {None}\")\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "test_features = None\n",
    "for fea in test_features:\n",
    "    print(f\"Feature: {fea}, Type: {None}\")\n",
    "\n",
    "print(f\"\\nDifference between train_features and test_features: {None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 [2pts] Feature analysis\n",
    "\n",
    "# Fill in None in the following code.\n",
    "\n",
    "def feature_analysis(df, features):\n",
    "    for fea in features:\n",
    "        fea_name = fea.ljust(11, \" \")\n",
    "        if df[fea].dtype != object:\n",
    "            print(\n",
    "                f\"Feature: {fea_name},\\t Type: {None},\\t\",\n",
    "                f\"Min: {round(None, 3)},\\t Max: {round(None, 3)},\\t\",\n",
    "                f\"Mean: {round(None, 3)},\\t Std: {round(None, 3)},\\t\",\n",
    "                f\"unique_num: {None}, \\t null_num: {None}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"-\"*100,\n",
    "                f\"\\nFeature: {fea_name},\\t Type: {None},\\t\",\n",
    "                f\"unique_num: {None},\\t null_num: {None}\"\n",
    "            )\n",
    "            unique_value_list = None\n",
    "            for value in unique_value_list:\n",
    "                print(f\"value: {value},\\t num: {(df[fea] == value).sum()}\")\n",
    "            print(\"-\"*100)\n",
    "\n",
    "print(\"Training data:\")\n",
    "feature_analysis(train_df, train_features)\n",
    "\n",
    "print(f\"\\n{'='*130}\\n\")\n",
    "print(\"Test data:\")\n",
    "feature_analysis(test_df, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 [2pts] Feature encoder\n",
    "\n",
    "# Hint: use sklearn.preprocessing.LabelEncoder\n",
    "\n",
    "for fea in train_features:\n",
    "    if train_df[fea].dtype == object:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 [2pts] Feature distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart for activity in training data\n",
    "plt.bar() # TODO\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Activity in Training Data')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for heart_rate in training data\n",
    "sns.histplot() # TODO\n",
    "plt.xlabel('Heart Rate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Heart Rate in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 [2pts] Heatmap of feature correlation\n",
    "\n",
    "sns.heatmap() # TODO\n",
    "plt.title('Feature Correlation of Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2    [15pts] K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train = train_df.values[:, :-2].astype(np.float64)\n",
    "y_train = train_df.values[:, -2].astype(np.int32)\n",
    "\n",
    "X_test = test_df.values[:, :-1].astype(np.float64)\n",
    "y_test = test_df.values[:, -1].astype(np.int32)\n",
    "\n",
    "X_train = normalize(X_train, axis=0, norm=\"max\")\n",
    "X_test = normalize(X_test, axis=0, norm=\"max\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using sklearn, we can implement Logistic Regression easily \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(C=1.0, max_iter=500)\n",
    "\n",
    "lr_model.fit(X_train, y_train) \n",
    "# predicted probability on test set using logistic regression model\n",
    "y_pred_train_lr = lr_model.predict(X_train)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)\n",
    "y_pred_test_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_lr), accuracy_score(y_test, y_pred_test_lr), roc_auc_score(y_test, y_prob_lr, multi_class='ovr'))) \n",
    "\n",
    "## However, we do not consider the hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 [6pts] K-fold Cross Validation using accuracy\n",
    "## Choosing the hyper parameter C\n",
    "\n",
    "num_folds = 5\n",
    "C_choices = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# A dictionary holding the accuracies for different values of C that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# C_to_accuracies[C] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of C.\n",
    "C_to_accuracies = dict()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of C. For each        #\n",
    "# possible value of C, run the LogisticRegression algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of C in the C_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for C in sorted(C_to_accuracies):\n",
    "    for accuracy in C_to_accuracies[C]:\n",
    "        print('C = %.2f, accuracy = %f' % (C, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 [2pts] Plot the result of 2.1\n",
    "\n",
    "# plot the raw observations\n",
    "for idx, C in enumerate(C_choices, 1):\n",
    "    accuracies = C_to_accuracies[C]\n",
    "    plt.scatter([math.log10(C)] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for _,v in sorted(C_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for _,v in sorted(C_to_accuracies.items())])\n",
    "plt.errorbar([math.log10(i) for i in C_choices], accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on C with accuracy')\n",
    "plt.xlabel('log C')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the result, which C value will you choose?\n",
    "[Put your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 2.3 [5pts] K-fold Cross Validation using AUC\n",
    "\n",
    "num_folds = 5\n",
    "C_choices = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# A dictionary holding the accuracies for different values of C that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# C_to_AUC[C] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of C.\n",
    "C_to_AUC = dict()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of C. For each        #\n",
    "# possible value of C, run the LogisticRegression algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of C in the C_to_AUC dictionary.                                      #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# Print out the computed AUCs\n",
    "for C in sorted(C_to_AUC):\n",
    "    for accuracy in C_to_AUC[C]:\n",
    "        print('C = %.2f, auc = %f' % (C, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 [2pts] Plot the result of 2.3\n",
    "\n",
    "# plot the raw observations\n",
    "for idx, C in enumerate(C_choices, 1):\n",
    "    accuracies = C_to_AUC[C]\n",
    "    plt.scatter([math.log10(C)] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "AUCs_mean = np.array([np.mean(v) for _,v in sorted(C_to_AUC.items())])\n",
    "AUCs_std = np.array([np.std(v) for _,v in sorted(C_to_AUC.items())])\n",
    "plt.errorbar([math.log10(i) for i in C_choices], AUCs_mean, yerr=AUCs_std)\n",
    "plt.title('Cross-validation on C with AUC')\n",
    "plt.xlabel('log C')\n",
    "plt.ylabel('Cross-validation AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the result, which C value will you choose?\n",
    "[Put your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 [15pts] Various Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using C=10, we can get a better LogisticRegression model\n",
    "\n",
    "lr_model = LogisticRegression(C=10, max_iter=500)\n",
    "lr_model.fit(X_train, y_train) \n",
    "y_pred_train_lr = lr_model.predict(X_train)\n",
    "y_pred_test_lr = lr_model.predict(X_test) \n",
    "y_prob_lr = lr_model.predict_proba(X_test)\n",
    "print(\"Logistic Regression:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_lr), accuracy_score(y_test, y_pred_test_lr), roc_auc_score(y_test, y_prob_lr, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 [2pts] Tree model\n",
    "\n",
    "tree_model = None\n",
    "\n",
    "y_pred_train_tree = None\n",
    "y_pred_test_tree = None\n",
    "y_prob_tree = None\n",
    "\n",
    "print(\"Decision Tree:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_tree), accuracy_score(y_test, y_pred_test_tree), roc_auc_score(y_test, y_prob_tree, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 [2pts] Multi- Layer Perceptron\n",
    "\n",
    "MLP_model = None\n",
    "\n",
    "y_pred_train_mlp = None\n",
    "y_pred_test_mlp = None\n",
    "y_prob_mlp = None\n",
    "\n",
    "print(\"MLP:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_mlp), accuracy_score(y_test, y_pred_test_mlp), roc_auc_score(y_test, y_prob_mlp, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 [2pts] Support Vector Machine\n",
    "\n",
    "svm_model = None\n",
    "\n",
    "y_pred_train_svm = None\n",
    "y_pred_test_svm = None\n",
    "y_prob_svm = None\n",
    "\n",
    "print(\"SVM:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_svm), accuracy_score(y_test, y_pred_test_svm), roc_auc_score(y_test, y_prob_svm, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 [2pts] Naive Bayes\n",
    "\n",
    "bayesian_model = None\n",
    "\n",
    "y_pred_train_nb = None\n",
    "y_pred_test_nb = None\n",
    "y_prob_nb = None\n",
    "\n",
    "print(\"Naive Bayes:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_nb), accuracy_score(y_test, y_pred_test_nb), roc_auc_score(y_test, y_prob_nb, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 [2pts] Random Forest\n",
    "\n",
    "rf_model = None\n",
    "\n",
    "y_pred_train_rf = None\n",
    "y_pred_test_rf = None\n",
    "y_prob_rf = None\n",
    "\n",
    "print(\"Random Forest:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_rf), accuracy_score(y_test, y_pred_test_rf), roc_auc_score(y_test, y_prob_rf, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 [2pts] LightGBM\n",
    "\n",
    "LightGBM_model = None\n",
    "\n",
    "y_pred_train_gbm = None\n",
    "y_pred_test_gbm = None\n",
    "y_prob_gbm = None\n",
    "\n",
    "print(\"LightGBM:\\t acc on train is %.4f ; acc on test is %.4f ; AUC on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_gbm), accuracy_score(y_test, y_pred_test_gbm), roc_auc_score(y_test, y_prob_gbm, multi_class='ovr'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 [3pts] Plot ROCs in one image\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Plot the ROC on test set using ovr for all models above                      #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the result, which model performs well?\n",
    "[Put your answer here]\n",
    "- And which model performs poor?\n",
    "[Put your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 [15pts] Model Combination Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 [5pts] Voting\n",
    "\n",
    "y_pred_train_voting = None\n",
    "y_pred_test_voting = None\n",
    "\n",
    "print(\"Voting strategy:\\t acc on train is %.4f ; acc on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_voting), accuracy_score(y_test, y_pred_test_voting))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 [10pts] Stacking\n",
    "\n",
    "y_pred_train_stacking = None\n",
    "y_pred_test_stacking = None\n",
    "\n",
    "print(\"Stacking strategy:\\t acc on train is %.4f ; acc on test is %.4f\" \n",
    "        %(accuracy_score(y_train, y_pred_train_stacking), accuracy_score(y_test, y_pred_test_stacking)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 [45pts] Regression Task in Practice\n",
    "\n",
    "Write your code below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
